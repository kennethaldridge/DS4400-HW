{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "483eb75f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from numpy import genfromtxt\n",
    "from sklearn.preprocessing import MinMaxScaler"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5396526c",
   "metadata": {},
   "source": [
    "# Question 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c86eb9ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "A = genfromtxt('life_expectancy_X.csv', delimiter=',')\n",
    "A_test = genfromtxt('life_expectancy_X_test.csv', delimiter=',')\n",
    "\n",
    "y = genfromtxt('life_expectancy_y.csv', delimiter=',')\n",
    "y_test = genfromtxt('life_expectancy_y_test.csv', delimiter=',')\n",
    "\n",
    "# Scale\n",
    "scaler = MinMaxScaler()\n",
    "A = scaler.fit_transform(A)\n",
    "A_test = scaler.transform(A_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e844796",
   "metadata": {},
   "source": [
    "### 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "cca66412",
   "metadata": {},
   "outputs": [],
   "source": [
    "def f_prime(w, phi, y, l1_lambda):\n",
    "    return (1/len(phi))*(phi.T @ (phi@w - y)) + l1_lambda * np.sign(w)\n",
    "\n",
    "def gradient_descent(phi, y, w, eta, num_iterations, l1_lambda):\n",
    "\tfor i in range(num_iterations):\n",
    "\t\tw = w - eta * f_prime(w, phi, y, l1_lambda)  \n",
    "            \n",
    "\treturn w\n",
    "\n",
    "def mse_func(phi, w, y):\n",
    "\treturn np.mean((phi@w - y)**2)\n",
    "\n",
    "def sorted_features_importance(feature_names_list, w):\n",
    "\tsorted_w = w[:-1]\n",
    "\n",
    "\tsorted_indices = np.argsort(-np.abs(sorted_w))\n",
    "\tsorted_features = [feature_names_list[i] for i in sorted_indices]\n",
    "\tsorted_w = w[sorted_indices]\n",
    "\n",
    "\tfor feature, weight in zip(sorted_features, sorted_w):\n",
    "\t\tprint(f\"{feature}: {weight:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "c29b8149",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: 0.005947909788639809\n"
     ]
    }
   ],
   "source": [
    "phi = np.hstack((np.ones((A.shape[0], 1)), A))\n",
    "w0 = np.zeros(phi.shape[1])\n",
    "eta = 0.02\n",
    "l1_lambda = 0.01\n",
    "\n",
    "w = gradient_descent(phi, y, w0, eta, 10000, l1_lambda)\n",
    "\n",
    "phi_test = np.hstack((np.ones((A_test.shape[0], 1)), A_test))\n",
    "\n",
    "print(f'MSE: {mse_func(phi_test, w, y_test)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2dc4b44c",
   "metadata": {},
   "source": [
    "### 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "577e9cd5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exercise amount: 57.7919\n",
      "Amount of supportive relationships: 27.2238\n",
      "Number of siblings: 12.1992\n",
      "Height: -1.2059\n",
      "Attractiveness: 0.0121\n",
      "Alcohol / Drugs / Smoking consumption: 0.0086\n",
      "work ethics: 0.0040\n"
     ]
    }
   ],
   "source": [
    "feature_names = [\n",
    "    \"Exercise amount\",\n",
    "    \"Amount of supportive relationships\",\n",
    "    \"Number of siblings\",\n",
    "    \"Alcohol / Drugs / Smoking consumption\",\n",
    "    \"Height\",\n",
    "    \"Attractiveness\",\n",
    "    \"work ethics\"\n",
    "]\n",
    "\n",
    "sorted_features_importance(feature_names, w)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3aab76f5",
   "metadata": {},
   "source": [
    "Biggest Positive Impact: Exercise Amount, Supportive Relationshops, Number of Siblings  \n",
    "Negative Impact: Height  \n",
    "Attractiveness, Alcohol/Drugs/Smoking, and Work Ethic all have a minimal impact on longetivty  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b35ef0b",
   "metadata": {},
   "source": [
    "### 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5866147",
   "metadata": {},
   "outputs": [],
   "source": [
    "def center_func(n):\n",
    "      C = np.eye(n) - (1/n) * np.ones((n, n))\n",
    "      return C\n",
    "\n",
    "def pca_reduc_func(X, num_dimensions):\n",
    "    n = len(X)\n",
    "\n",
    "    C = center_func(n)\n",
    "    Q = X.T @ C @ X\n",
    "\n",
    "    [D, V] = np.linalg.eigh(Q)\n",
    "\n",
    "    v = V[:, -num_dimensions:]\n",
    "\n",
    "    X_hat = (C @ X) @ v \n",
    "\n",
    "    return X_hat, v \n",
    "\n",
    "def f_prime(w, phi, y):\n",
    "    return (1/len(phi))*(phi.T @ (phi@w - y))\n",
    "\n",
    "def gradient_descent(phi, y, w, eta, num_iterations):\n",
    "    for i in range(num_iterations):\n",
    "        w = w - eta * f_prime(w, phi, y)  \n",
    "\n",
    "        if i % 1000 == 0:\n",
    "            mse = np.mean((phi @ w - y)**2)\n",
    "            print(f\"Iter {i}, MSE={mse:.2f}\")\n",
    "\n",
    "    return w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "91ccbf25",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 0, MSE=5471.17\n",
      "Iter 1000, MSE=54.17\n",
      "Iter 2000, MSE=54.16\n",
      "Iter 3000, MSE=54.16\n",
      "Iter 4000, MSE=54.16\n",
      "Iter 5000, MSE=54.16\n",
      "Iter 6000, MSE=54.16\n",
      "Iter 7000, MSE=54.16\n",
      "Iter 8000, MSE=54.16\n",
      "Iter 9000, MSE=54.16\n",
      "Iter 10000, MSE=54.16\n",
      "Iter 11000, MSE=54.16\n",
      "Iter 12000, MSE=54.16\n",
      "Iter 13000, MSE=54.16\n",
      "Iter 14000, MSE=54.16\n",
      "Iter 15000, MSE=54.16\n",
      "Iter 16000, MSE=54.16\n",
      "Iter 17000, MSE=54.16\n",
      "Iter 18000, MSE=54.16\n",
      "Iter 19000, MSE=54.16\n",
      "MSE: 54.160849392578356\n"
     ]
    }
   ],
   "source": [
    "pca_A, pca_v = pca_reduc_func(A, 4)\n",
    "\n",
    "pca_phi = np.hstack((np.ones((pca_A.shape[0], 1)), pca_A))\n",
    "w0 = np.zeros(pca_phi.shape[1])\n",
    "eta = 0.05\n",
    "\n",
    "pca_w = gradient_descent(pca_phi, y, w0, eta, 20000)\n",
    "\n",
    "A_test_C = center_func(len(A_test))\n",
    "pca_A_test = A_test @ pca_v\n",
    "\n",
    "pca_phi_test = np.hstack((np.ones((pca_A_test.shape[0], 1)), pca_A_test))\n",
    "# print(f'MSE: {mse_func(pca_phi_test, pca_w, y_test)}')\n",
    "print(f'MSE: {mse_func(pca_phi, pca_w, y)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "133424aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train MSE: 54.1608\n",
      "Test MSE: 50.2073\n"
     ]
    }
   ],
   "source": [
    "def pca_reduc_func(X, num_dimensions):\n",
    "    mean = np.mean(X, axis=0)\n",
    "    X_centered = X - mean\n",
    "\n",
    "    Q = X_centered.T @ X_centered\n",
    "    D, V = np.linalg.eigh(Q)\n",
    "    v = V[:, -num_dimensions:]\n",
    "\n",
    "    X_hat = X_centered @ v\n",
    "    return X_hat, v, mean\n",
    "\n",
    "def apply_pca(X, v, mean):\n",
    "    return (X - mean) @ v\n",
    "\n",
    "pca_A, pca_v, pca_mean = pca_reduc_func(A, 4)\n",
    "\n",
    "# Add bias term AFTER projection\n",
    "pca_phi = np.hstack((np.ones((pca_A.shape[0], 1)), pca_A))\n",
    "\n",
    "# Initialize weights to 0\n",
    "w0 = np.zeros(pca_phi.shape[1])\n",
    "eta = 0.05\n",
    "pca_w = gradient_descent(pca_phi, y, w0, eta, 20000)\n",
    "\n",
    "# Predict on training set\n",
    "train_mse = mse_func(pca_phi, pca_w, y)\n",
    "print(f\"Train MSE: {train_mse:.4f}\")\n",
    "\n",
    "# Transform test set using same PCA basis and mean\n",
    "pca_A_test = apply_pca(A_test, pca_v, pca_mean)\n",
    "pca_phi_test = np.hstack((np.ones((pca_A_test.shape[0], 1)), pca_A_test))\n",
    "test_mse = mse_func(pca_phi_test, pca_w, y_test)\n",
    "print(f\"Test MSE: {test_mse:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e14cb7e4",
   "metadata": {},
   "source": [
    "### 4)\n",
    "PCA is a good idea for this problem because it projects the data onto the most important dimensions. For this problem, the linear regression weights of attractiveness, alcohol/drugs consumption, and work ethic are all very small and don't have much significance to the predicted label. There are 4 weights that do make an impact, so projecting the data down to just 4 dimensions make sense. Once the data is projected, the noise and less impactful dimensions are removed, and it is easier to run linear regression and other algorithms."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "7e654f15",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.850862923961672, 0.43643566943178946, 0.0024597524148604446, -0.31227345199114964, -0.03625414381613679, -0.034824150075934056, 0.031364032485239474]\n"
     ]
    }
   ],
   "source": [
    "corr_list = []\n",
    "for xi in A.T:\n",
    "    corr = np.corrcoef(xi, y)[0, 1]\n",
    "    corr_list.append(corr)\n",
    "\n",
    "print(corr_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f80eaef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exercise amount: 0.8509\n",
      "Amount of supportive relationships: 0.4364\n",
      "Alcohol / Drugs / Smoking consumption: -0.3123\n",
      "Height: -0.0363\n",
      "Attractiveness: -0.0348\n",
      "Number of siblings: 0.0025\n"
     ]
    }
   ],
   "source": [
    "# Check correlations with feature names\n",
    "feature_names = [\n",
    "    \"Exercise amount\",\n",
    "    \"Amount of supportive relationships\",\n",
    "    \"Number of siblings\",\n",
    "    \"Alcohol / Drugs / Smoking consumption\",\n",
    "    \"Height\",\n",
    "    \"Attractiveness\",\n",
    "    \"work ethics\"\n",
    "]\n",
    "\n",
    "sorted_features_importance(feature_names, np.array(corr_list))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ds",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
